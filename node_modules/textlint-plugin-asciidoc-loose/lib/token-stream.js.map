{"version":3,"sources":["../src/token-stream.js"],"names":[],"mappings":";AACA;;;;;QAKgB,iB,GAAA,iB;;AAJhB;;;;AACA;;;;AACA,IAAM,WAAW,8BAAjB;AACA,IAAM,UAAU,SAAS,uBAAT,CAAiC,YAAY,mCAA7C,CAAhB;AACO,SAAS,iBAAT,CAA2B,IAA3B,EAAiC;AACpC,QAAM,SAAS,+BAAoB,IAApB,CAAf;AACA,QAAM,YAAY,EAAlB;AACA,QAAM,QAAQ,KAAK,KAAL,CAAW,IAAX,CAAd;AACA,QAAI,YAAY,IAAhB;AACA,QAAI,iBAAiB,CAArB;AACA,UAAM,OAAN,CAAc,gBAAQ;;AAElB,YAAM,SAAS,QAAQ,YAAR,CAAqB,IAArB,EAA2B,SAA3B,CAAf;AACA,aAAK,IAAI,IAAI,CAAb,EAAgB,IAAI,OAAO,MAAP,CAAc,MAAlC,EAA0C,GAA1C,EAA+C;AAC3C,gBAAM,QAAQ,OAAO,MAAP,CAAc,CAAd,CAAd;AACA,kBAAM,UAAN,IAAoB,cAApB;AACA,kBAAM,QAAN,IAAkB,cAAlB;AACA,kBAAM,GAAN,GAAY;AACR,uBAAO,OAAO,eAAP,CAAuB,MAAM,UAA7B,CADC;AAER,qBAAK,OAAO,eAAP,CAAuB,MAAM,QAA7B;AAFG,aAAZ;AAIA,sBAAU,IAAV,CAAe,KAAf;AACH;AACD,oBAAY,OAAO,SAAnB;AACA,0BAAmB,KAAK,MAAL,GAAc,CAAjC;AACH,KAfD;AAgBA,WAAO,SAAP;AACH","file":"token-stream.js","sourcesContent":["// LICENSE : MIT\n\"use strict\";\nimport SourceStructure from \"structured-source\";\nimport {Registry} from 'vscode-textmate';\nconst registry = new Registry();\nconst grammar = registry.loadGrammarFromPathSync(__dirname + '/../syntax/Asciidoctor.tmLanguage');\nexport function createTokenStream(text) {\n    const source = new SourceStructure(text);\n    const tokenList = [];\n    const lines = text.split(\"\\n\");\n    var ruleStack = null;\n    let lineStartIndex = 0;\n    lines.forEach(line => {\n        // prev rule stack\n        const parsed = grammar.tokenizeLine(line, ruleStack);\n        for (let i = 0; i < parsed.tokens.length; i++) {\n            const token = parsed.tokens[i];\n            token.startIndex += lineStartIndex;\n            token.endIndex += lineStartIndex;\n            token.loc = {\n                start: source.indexToPosition(token.startIndex),\n                end: source.indexToPosition(token.endIndex)\n            };\n            tokenList.push(token);\n        }\n        ruleStack = parsed.ruleStack;\n        lineStartIndex += (line.length + 1);\n    });\n    return tokenList;\n}\n"]}